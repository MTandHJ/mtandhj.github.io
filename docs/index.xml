<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MTandHJ</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on MTandHJ</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Finite Scalar Quantization: VQ-VAE Made Simple</title>
      <link>http://localhost:1313/posts/fsq/</link>
      <pubDate>Wed, 12 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/fsq/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.mtandhj.com/posts/vqvae/&#34;&gt;VQ-VAE&lt;/a&gt; 提供了一种优雅的向量量化 (离散化表示) 的一种方式, 然而其中的 codebook 的训练以及前置的 encoder 的训练依赖 stop gradient ($\text{sg}(\cdot)$) 以及 straight-through estimator (STE) 操作, 这会导致训练起来比较困难. 具体来说, 可能:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;codebook 中的部分向量过于接近, 从而冗余;&lt;/li&gt;&#xA;&lt;li&gt;很多向量在训练过程中完全不会匹配到任何向量.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;习惯上, 我们称训练过程中发生了 Codebook Collapse 的问题.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;以及有不少文章注意到并且提出了一些解决方案 (包括本文), 我们对部分文章一笔带过:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;[1] 中对会对那些长期不产生匹配的向量进行重新初始化;&lt;/li&gt;&#xA;&lt;li&gt;[2] 主要正对 codebook 的初始化, 不似一般的随机初始化, 其提出根据初始的数据分布, 通过 K-Means++ 进行一个初步的初始化, 并且强调了 scaling 的重要性;&lt;/li&gt;&#xA;&lt;li&gt;[3] 中提出了一种随机量化的方法, 本质上用 Gumbel-softmax 替代 STE.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;核心思想&#34;&gt;核心思想&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250312145029.png&#34; alt=&#34;20250312145029&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;注意到, 一般的向量量化 (VQ) 需要一个&lt;strong&gt;显式的可训练的&lt;/strong&gt; codebook $\mathcal{C} = \{c_k\}_{k=1}^K$, 然后给定一个隐变量 $z \in \mathbb{R}^d$, 通过&lt;/p&gt;&#xA;$$&#xD;&#xA;    z_q = \text{argmin}_{c \in \mathcal{C}} \|z - c\|&#xD;&#xA;    $$&lt;p&gt;来进行一个量化.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Taming Transformers for High-Resolution Image Synthesis</title>
      <link>http://localhost:1313/posts/vqgan/</link>
      <pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/vqgan/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在学习 VQGAN 之前, 请务必先了解 &lt;a href=&#34;https://www.mtandhj.com/posts/vqvae/&#34;&gt;VQ-VAE&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;核心思想&#34;&gt;核心思想&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250311144000.png&#34; alt=&#34;20250311144000&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Transformer 已经在 NLP 领域取得了巨大的进展, 本文想要开发其在图像生成领域的能力.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;part1-离散编码&#34;&gt;Part1: 离散编码&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;既然 Transformer 的成功依赖离散的 token, 那么通过它来生成图片很重要的一个点是如何将图片离散化? 于是乎, 作者引入了 VQGAN 来得到图片的离散编码.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;给定一个图片 $x \in \mathbb{R}^{H \times W \times 3}$, 首先通过一个 &lt;strong&gt;CNN&lt;/strong&gt; encoder $E$ 来得到初步的编码:&lt;/p&gt;&#xA;$$&#xD;&#xA;    \hat{z} = E(x) \in \mathbb{R}^{h \times w \times n_z}.&#xD;&#xA;    $$&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;接着, element-wise 地为每一个&amp;rsquo;像素点&amp;rsquo;匹配它的 token:&lt;/p&gt;&#xA;$$&#xD;&#xA;    z_{\mathbf{q}} = \mathbf{q}(\hat{z}) := \bigg(\text{argmin}_{z_k \in \mathcal{Z}} \|\hat{z}_{ij} - z_k\| \bigg)_{ij},&#xD;&#xA;    $$&lt;p&gt;这里 $\mathcal{Z} = \{z_k\}_{k=1}^K \subset \mathbb{R}^{n_z}$, 俗称 codebook.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural Discrete Representation Learning</title>
      <link>http://localhost:1313/posts/vqvae/</link>
      <pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/vqvae/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;作者的目的是实现离散化的表示学习: 给定任意的模式, 编码成离散的表示.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;既然本文是居于 VAE (变分自编码) 的框架实现的, 我们得对变分自编码有一个初步的了解. VAE 主要包含三个模块:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Encoder $\phi$: 它讲输入 $x \in \mathbb{R}^D$ 映射到一个分布:&lt;/p&gt;&#xA;$$&#xD;&#xA;        q(z|x; \phi).&#xD;&#xA;        $$&lt;p&gt;比如当服从的高斯分布, 实质上 $\phi(x) \rightarrow (\mu, \sigma) \rightarrow \mathcal{N}(\mu, \sigma^2)$, 然后 $z$ 从该分布中采样即可;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Decoder $\Phi$: 它将隐变量 $z$ 映射回 (通常来说) $x$ 的空间:&lt;/p&gt;&#xA;$$&#xD;&#xA;        p(x|z; \Phi);&#xD;&#xA;        $$&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;还有一个先验分布 $p(z)$ 用于辅助训练.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;VAE 的训练目标是极大似然的一个下界:&lt;/p&gt;&#xA;$$&#xD;&#xA;    \begin{align*}&#xD;&#xA;    \log p(x) &#xD;&#xA;    &amp;= \log \int p(x, z) \mathrm{d}z \\&#xD;&#xA;    &amp;= \log \int q(z|x; \phi) \cdot \frac{p(x, z)}{q(z|x; \phi)} \mathrm{d}z \\&#xD;&#xA;    &amp;= \log \int q(z|x; \phi) \cdot \frac{p(x| z; \Phi) p(z)}{q(z|x; \phi)} \mathrm{d}z \\&#xD;&#xA;    &amp;\ge \int q(z|x; \phi) \log \frac{p(x| z; \Phi) p(z)}{q(z|x; \phi)} \mathrm{d}z \\&#xD;&#xA;    &amp;= \int q(z|x; \phi) \log \frac{p(z)}{q(z|x; \phi)} \mathrm{d}z +&#xD;&#xA;    \int q(z|x; \phi) \log p(x|z; \Phi) \mathrm{d}z \\&#xD;&#xA;    &amp;= \underbrace{-\mathbf{KL}(q_{\phi}\| p(z)) +&#xD;&#xA;    \mathbb{E}_{z \sim q_{\phi}} \log p(x|z; \Phi)}_{\text{ELBO}}.&#xD;&#xA;    \end{align*}&#xD;&#xA;    $$&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ELBO 包括一个和先验分布的 KL 散度 (这部分通常是增加隐变量的 diversity 的), 以及一个正常的交叉熵 (如果 $p_{\Phi}$ 也是一个高斯, 则通常称之为重构损失).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Slide-test</title>
      <link>http://localhost:1313/slides/test/</link>
      <pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/slides/test/</guid>
      <description>&lt;section data-markdown&gt;&#xD;&#xA;  # 第一页&#xD;&#xA;&lt;p&gt;这是第一页的内容看看看看看阿卡看看看看看看看看看看看看看看看看看看看看看看看&lt;/p&gt;&#xA;&lt;/section&gt;&#xD;&#xA;&lt;section data-markdown&gt;&#xD;&#xA;  &lt;textarea data-template&gt;&#xD;&#xA;  ### dier&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;为什么没有 bullet&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ddd&#xA;$$&#xD;&#xA;    x + 1&#xD;&#xA;    $$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;5ddd&#xA;&lt;/textarea&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/section&gt;&#xD;&#xA;&lt;section data-markdown&gt;&#xD;&#xA;  &lt;textarea data-template&gt;&#xD;&#xA;  ### 333&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;为什么没有 bullet&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ddd&#xA;$$&#xD;&#xA;    x + 1&#xD;&#xA;    $$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;5ddd&#xA;&lt;/textarea&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/section&gt;</description>
    </item>
    <item>
      <title>Git</title>
      <link>http://localhost:1313/posts/git/</link>
      <pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/git/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.liaoxuefeng.com/wiki/896043488029600&#34;&gt;廖雪峰Git教程&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在你想要git的文件夹内 git bash here&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;接着注册&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git config --global user.name &amp;#34;XXXXXX&amp;#34;&#xD;&#xA;git config --global user.email &amp;#34;XXX@+++.com&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;配置别名&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git config --global alias.last &amp;#39;log -1&amp;#39;&#xD;&#xA;git config --global alias.lg &amp;#34;log --color --graph --pretty=format:&amp;#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&amp;lt;%an&amp;gt;%Creset&amp;#39; --abbrev-commit&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;上面的步骤是第一次使用git, 若不是可省略&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将所在目录变成git可以管理的仓库&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git init&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在所在目录添加 .gitignore 文件, 一般可以直接在&lt;a href=&#34;https://github.com/github/gitignore&#34;&gt;这儿&lt;/a&gt;选择所需要的就行, 特殊情况可以自己再加点定制&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git add .gitignore&#xD;&#xA;git commit -m &amp;#34;add .gitignore&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;远程仓库&#34;&gt;远程仓库&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;创建ssh key&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh-keygen -t rsa -C &amp;#34;xxx@+++.com&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后在主目录下找到.ssh目录里面的id_rsa.pub (公钥), 并复制文件里的内容.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在GitHub的settings里面找到ssh keys (SSH and GPG keys)部分添加new ssh key&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
