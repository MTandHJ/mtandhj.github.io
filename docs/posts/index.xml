<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on MTandHJ</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Blogs on MTandHJ</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 16 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Autoregressive Image Generation using Residual Quantization</title>
      <link>http://localhost:1313/posts/rqvae/</link>
      <pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/rqvae/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;请务必了解 &lt;a href=&#34;https://www.mtandhj.com/posts/vqvae/&#34;&gt;VQ-VAE&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;核心思想&#34;&gt;核心思想&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250316155423.png&#34; alt=&#34;20250316155423&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;RQ-VAE 自称也是为了解决所谓的 &lt;a href=&#34;https://www.mtandhj.com/posts/fsq/#%e9%a2%84%e5%a4%87%e7%9f%a5%e8%af%86&#34;&gt;codebook collapse&lt;/a&gt; 问题, 即当 codebook size 逐渐增加的时候, 或有越来越多的向量变得&amp;quot;冗余&amp;quot;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;另一方面, 如果我们减少 codebook size, 很容易相当在向量量化的过程会造成非常大的信息损耗. 于是, 本文提出了 RQ-VAE, 本质上是一个向量逐步地匹配 $D$ 个向量, 而非 one-to-one 的模式.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;RQ-VAE 的过程可以如此形式化:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;给定图片输入 $\mathbf{X} \in \mathbb{R}^{H_o \times W_o \times 3}$;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;经过 Encoder $E$ 得到&lt;/p&gt;&#xA;$$&#xD;&#xA;        \mathbf{Z} = E(\mathbf{X}) \in \mathbb{R}^{&#xD;&#xA;            \underbrace{H_o / f}_{=: H} \times &#xD;&#xA;            \underbrace{W_o / f}_{=: W} \times &#xD;&#xA;            n_z&#xD;&#xA;        };&#xD;&#xA;        $$&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;给定 codebook $\mathcal{C} = \{\mathbf{e}_k\}_{k \in [K]}$, 进行向量量化:&lt;/p&gt;&#xA;$$&#xD;&#xA;        Q(\mathbf{z} \in \mathbb{R}^{n_z}; \mathcal{C})&#xD;&#xA;        = \text{argmin}_{k \in [K]} \|\mathbf{z} - \mathbf{e}_k \|_2^2,&#xD;&#xA;        $$&lt;p&gt;对于 $\mathbf{Z}$ 来说, 可以得到如下的 codes:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Recommender Systems with Generative Retrieval</title>
      <link>http://localhost:1313/posts/tiger/</link>
      <pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/tiger/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;请了解 &lt;a href=&#34;https://www.mtandhj.com/posts/rqvae/&#34;&gt;RQ-VAE&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;核心思想&#34;&gt;核心思想&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250316175829.png&#34; alt=&#34;20250316175829&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;目前主流的推荐系统的一个痛点是将 item 表示为一个 embedding, 这就导致对于冷启动的场景并不友好 (既然我们没法再立即获得高效的新来的 item 的表示). 此外, 现阶段的推荐系统大多采用 matching 的架构 (在 item 数量较多的时候可能会慢一些), 本文探索一种生成式的检索方式.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;本文所提出的 Tiger 依然 RQ-VAE, 对 item 的文本 embedding 首先进行编码, 得到的编码作为 item 的 &amp;lsquo;ID&amp;rsquo;, 后面的模型只需要在此基础上进行预测即可.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250316175859.png&#34; alt=&#34;20250316175859&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如上图所示, 文本的 embedding 经过 RQ-VAE (codebook 不共享) 得到 semantic codes. 比如 codebook 的size 为 8, 则理论上可以表示 $8^K$ 个 items (这里 $K$ 表示残差量化的次数).&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在第一阶段训练完毕之后, 我们就可以用得到的编码作为每个 item 的 &amp;lsquo;ID&amp;rsquo;, 然后就可以训练一个模型来进行生成式推荐, 这里文中给了一个例子:&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250316180725.png&#34; alt=&#34;20250316180725&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对于一个新来的 item, 只需要 -&amp;gt; Tiger 编码 -&amp;gt; 就可以用于预测了.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;注:&lt;/strong&gt; 这里省略了避免 ID 碰撞的细节.&lt;/p&gt;</description>
    </item>
    <item>
      <title>中研春招聘小记</title>
      <link>http://localhost:1313/posts/%E4%B8%AD%E7%A0%94%E6%98%A525%E6%8B%9B%E8%81%98/</link>
      <pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E4%B8%AD%E7%A0%94%E6%98%A525%E6%8B%9B%E8%81%98/</guid>
      <description>&lt;h2 id=&#34;招聘布局&#34;&gt;招聘布局&lt;/h2&gt;&#xA;&lt;p&gt;此次招聘位于交大学术活动中心二楼的一角, 并不显眼, 外头也缺少足够的引导标志. 约莫着有三四十家高校和事业单位分列五排, 蓝白的布告栏竖在一张张桌子之后, 颇有严正以待的架势. 进门开始是东北大学的场地, 紧接着是荆楚学院、江西铜业技术研究院、某某集团. 较为心仪的嘉兴大学坐落在第三排的中部, 围满了一批批人. 其对面是第四排的丽水学院, 而第四排的尾部是南京理工大学. 转过去, 赫然便是湖南大学四个大字, 穿行而过是成都大学、中国警察学院、扬州大学以及坐落在角落的之江实验室.&lt;/p&gt;&#xA;&lt;h2 id=&#34;聊天过程&#34;&gt;聊天过程&lt;/h2&gt;&#xA;&lt;p&gt;称之为聊天过程而非是面试是因为一来本次主题是双选会, 二来本身也不指望能够凭借这场招聘会找到心仪的工作, 更多的是摸摸清楚自己到底几斤几两.&lt;/p&gt;&#xA;&lt;h3 id=&#34;江西铜业技术研究院&#34;&gt;江西铜业技术研究院&lt;/h3&gt;&#xA;&lt;p&gt;我上来盯着这家单位的布告栏看, 想看看这类研究院具体有个什么要求. 不过面前的小哥倒是很热情地邀请我坐下来聊一聊, 不过得知我对此并无兴趣之后我们就分道扬镳了.&lt;/p&gt;&#xA;&lt;h3 id=&#34;某医科单位&#34;&gt;某医科单位&lt;/h3&gt;&#xA;&lt;p&gt;很抱歉忘记具体的名字了, 负责招聘的人也是非常热情. 但是我说我的方向和医学可能八竿子打不着. 虽然上面也明确需要人工智能方面的人才, 但是大抵是需要医学图像的? 招聘人员拿着我的简历, 跳过了前面部分, 竟然直接跳到了&amp;quot;技能和语言&amp;quot;一栏, 说着 Python, PyTorch 和我们的需求挺符合的. 我感到奇怪, 我觉得这些是无关紧要的东西, 不过想来也能理解, 来招聘的多是为整个单位招人.&lt;/p&gt;&#xA;&lt;h3 id=&#34;南阳理工学院&#34;&gt;南阳理工学院&lt;/h3&gt;&#xA;&lt;p&gt;这个主要是跟在师妹边上旁听的, 只能说是大开眼界: 据招聘人来说, 他们学院可以非常痛快地给安家费, 然后每个月到手能到 13K (副教授待遇), 而且科研横向不收取管理费! 另外, 需要说明的是, 这 13K 如果后期考核不通过会降到 11K (但是招聘说这句话的时候明显咯噔了一些, 大概率存在猫腻).&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;优点:&lt;/strong&gt; 没有非升即走, 博士毕业点击就送, 安家费给的痛快, 考核要求很低&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;缺点:&lt;/strong&gt; 这类学院我个人都对他们是否能够长期维持存在疑问, 另外过于痛快总让我感觉其中有猫腻&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;丽水学院&#34;&gt;丽水学院&lt;/h3&gt;&#xA;&lt;p&gt;丽水学院的招聘老师人挺好, 也没啥架子. 比较有趣的是, 丽水学院里面设立了一个 &amp;ldquo;数学与计算机学院&amp;rdquo;, 我当时的第一个感觉就是这玩意儿可真有意思. 由于对地域不太感兴趣, 仅探听到了大约年薪十几万这个普遍的待遇条件.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Finite Scalar Quantization: VQ-VAE Made Simple</title>
      <link>http://localhost:1313/posts/fsq/</link>
      <pubDate>Wed, 12 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/fsq/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.mtandhj.com/posts/vqvae/&#34;&gt;VQ-VAE&lt;/a&gt; 提供了一种优雅的向量量化 (离散化表示) 的一种方式, 然而其中的 codebook 的训练以及前置的 encoder 的训练依赖 stop gradient ($\text{sg}(\cdot)$) 以及 straight-through estimator (STE) 操作, 这会导致训练起来比较困难. 具体来说, 可能:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;codebook 中的部分向量过于接近, 从而冗余;&lt;/li&gt;&#xA;&lt;li&gt;很多向量在训练过程中完全不会匹配到任何向量.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;习惯上, 我们称训练过程中发生了 Codebook Collapse 的问题.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;以及有不少文章注意到并且提出了一些解决方案 (包括本文), 我们对部分文章一笔带过:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;[1] 中对会对那些长期不产生匹配的向量进行重新初始化;&lt;/li&gt;&#xA;&lt;li&gt;[2] 主要正对 codebook 的初始化, 不似一般的随机初始化, 其提出根据初始的数据分布, 通过 K-Means++ 进行一个初步的初始化, 并且强调了 scaling 的重要性;&lt;/li&gt;&#xA;&lt;li&gt;[3] 中提出了一种随机量化的方法, 本质上用 Gumbel-softmax 替代 STE.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;核心思想&#34;&gt;核心思想&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250312145029.png&#34; alt=&#34;20250312145029&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;注意到, 一般的向量量化 (VQ) 需要一个&lt;strong&gt;显式的可训练的&lt;/strong&gt; codebook $\mathcal{C} = \{c_k\}_{k=1}^K$, 然后给定一个隐变量 $z \in \mathbb{R}^d$, 通过&lt;/p&gt;&#xA;$$&#xD;&#xA;    z_q = \text{argmin}_{c \in \mathcal{C}} \|z - c\|&#xD;&#xA;    $$&lt;p&gt;来进行一个量化.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Taming Transformers for High-Resolution Image Synthesis</title>
      <link>http://localhost:1313/posts/vqgan/</link>
      <pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/vqgan/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在学习 VQGAN 之前, 请务必先了解 &lt;a href=&#34;https://www.mtandhj.com/posts/vqvae/&#34;&gt;VQ-VAE&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;核心思想&#34;&gt;核心思想&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250311144000.png&#34; alt=&#34;20250311144000&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Transformer 已经在 NLP 领域取得了巨大的进展, 本文想要开发其在图像生成领域的能力.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;part1-离散编码&#34;&gt;Part1: 离散编码&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;既然 Transformer 的成功依赖离散的 token, 那么通过它来生成图片很重要的一个点是如何将图片离散化? 于是乎, 作者引入了 VQGAN 来得到图片的离散编码.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;给定一个图片 $x \in \mathbb{R}^{H \times W \times 3}$, 首先通过一个 &lt;strong&gt;CNN&lt;/strong&gt; encoder $E$ 来得到初步的编码:&lt;/p&gt;&#xA;$$&#xD;&#xA;    \hat{z} = E(x) \in \mathbb{R}^{h \times w \times n_z}.&#xD;&#xA;    $$&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;接着, element-wise 地为每一个&amp;rsquo;像素点&amp;rsquo;匹配它的 token:&lt;/p&gt;&#xA;$$&#xD;&#xA;    z_{\mathbf{q}} = \mathbf{q}(\hat{z}) := \bigg(\text{argmin}_{z_k \in \mathcal{Z}} \|\hat{z}_{ij} - z_k\| \bigg)_{ij},&#xD;&#xA;    $$&lt;p&gt;这里 $\mathcal{Z} = \{z_k\}_{k=1}^K \subset \mathbb{R}^{n_z}$, 俗称 codebook.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural Discrete Representation Learning</title>
      <link>http://localhost:1313/posts/vqvae/</link>
      <pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/vqvae/</guid>
      <description>&lt;h2 id=&#34;预备知识&#34;&gt;预备知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;作者的目的是实现离散化的表示学习: 给定任意的模式, 编码成离散的表示.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;既然本文是居于 VAE (变分自编码) 的框架实现的, 我们得对变分自编码有一个初步的了解. VAE 主要包含三个模块:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Encoder $\phi$: 它将输入 $x \in \mathbb{R}^D$ 映射到一个分布:&lt;/p&gt;&#xA;$$&#xD;&#xA;        q(z|x; \phi).&#xD;&#xA;        $$&lt;p&gt;比如当服从的高斯分布, 实质上 $\phi(x) \rightarrow (\mu, \sigma) \rightarrow \mathcal{N}(\mu, \sigma^2)$, 然后 $z$ 从该分布中采样即可;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Decoder $\Phi$: 它将隐变量 $z$ 映射回 (通常来说) $x$ 的空间:&lt;/p&gt;&#xA;$$&#xD;&#xA;        p(x|z; \Phi);&#xD;&#xA;        $$&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;还有一个先验分布 $p(z)$ 用于辅助训练.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;VAE 的训练目标是极大似然的一个下界:&lt;/p&gt;&#xA;$$&#xD;&#xA;    \begin{align*}&#xD;&#xA;    \log p(x) &#xD;&#xA;    &amp;= \log \int p(x, z) \mathrm{d}z \\&#xD;&#xA;    &amp;= \log \int q(z|x; \phi) \cdot \frac{p(x, z)}{q(z|x; \phi)} \mathrm{d}z \\&#xD;&#xA;    &amp;= \log \int q(z|x; \phi) \cdot \frac{p(x| z; \Phi) p(z)}{q(z|x; \phi)} \mathrm{d}z \\&#xD;&#xA;    &amp;\ge \int q(z|x; \phi) \log \frac{p(x| z; \Phi) p(z)}{q(z|x; \phi)} \mathrm{d}z \\&#xD;&#xA;    &amp;= \int q(z|x; \phi) \log \frac{p(z)}{q(z|x; \phi)} \mathrm{d}z +&#xD;&#xA;    \int q(z|x; \phi) \log p(x|z; \Phi) \mathrm{d}z \\&#xD;&#xA;    &amp;= \underbrace{-\mathbf{KL}(q_{\phi}\| p(z)) +&#xD;&#xA;    \mathbb{E}_{z \sim q_{\phi}} \log p(x|z; \Phi)}_{\text{ELBO}}.&#xD;&#xA;    \end{align*}&#xD;&#xA;    $$&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ELBO 包括一个和先验分布的 KL 散度 (这部分通常是增加隐变量的 diversity 的), 以及一个正常的交叉熵 (如果 $p_{\Phi}$ 也是一个高斯, 则通常称之为重构损失).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Git</title>
      <link>http://localhost:1313/posts/git/</link>
      <pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/git/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.liaoxuefeng.com/wiki/896043488029600&#34;&gt;廖雪峰Git教程&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在你想要git的文件夹内 git bash here&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;接着注册&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git config --global user.name &amp;#34;XXXXXX&amp;#34;&#xD;&#xA;git config --global user.email &amp;#34;XXX@+++.com&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;配置别名&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git config --global alias.last &amp;#39;log -1&amp;#39;&#xD;&#xA;git config --global alias.lg &amp;#34;log --color --graph --pretty=format:&amp;#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&amp;lt;%an&amp;gt;%Creset&amp;#39; --abbrev-commit&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;上面的步骤是第一次使用git, 若不是可省略&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将所在目录变成git可以管理的仓库&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git init&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在所在目录添加 .gitignore 文件, 一般可以直接在&lt;a href=&#34;https://github.com/github/gitignore&#34;&gt;这儿&lt;/a&gt;选择所需要的就行, 特殊情况可以自己再加点定制&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git add .gitignore&#xD;&#xA;git commit -m &amp;#34;add .gitignore&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;远程仓库&#34;&gt;远程仓库&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;创建ssh key&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh-keygen -t rsa -C &amp;#34;xxx@+++.com&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后在主目录下找到.ssh目录里面的id_rsa.pub (公钥), 并复制文件里的内容.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在GitHub的settings里面找到ssh keys (SSH and GPG keys)部分添加new ssh key&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
