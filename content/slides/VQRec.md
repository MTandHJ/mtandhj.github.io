---
date: "2025-07-09"
draft: false
title: "Is Vector Quantization the Future of Recommendation?"
author: MTandHJ
tags:
  - Slide
  - Vector Quantization
---

<section data-markdown>
## Is Vector Quantization the Future of Recommendation?
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### VQ-VAE

<div class="slide-img">
  <img 
  src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250707120708.png" 
  alt="Image" 
  style="max-width: 100%; height: auto;margin: 0 auto;">
</div>

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">van den Oord A., et al. Neural Discrete Representation Learning. NeurIPS, 2017.</p>
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### VQ-VAE

- **å‘é‡é‡åŒ–:**

    $$
    \bm{z} \rightarrow \bm{c}_{k^*}, \quad k^* = \text{argmin}_{k: \bm{c}_k \in \mathcal{C}} \|\bm{c}_k - \bm{z} \|.
    $$

- **STE** (straight-through estimator):

    $$
    \bm{q} = \text{STE}(\bm{c}_{k^*}) := \bm{z} + \textcolor{blue}{\text{sg}} \left(\bm{c}_{k^*} - \bm{z} \right) \\
    \text{d}\bm{q} = \text{d}{\bm{z}} + \underbrace{\text{d} \:{\text{sg} \left(\bm{c}_{k^*} - \bm{z} \right)}}_{=0}
    $$

- **Loss:**

    $$
    \mathcal{L} = \underbrace{\| g(\bm{q}) - \bm{x} \|_F^2}_{\mathcal{L}_{recon}} + 
    \underbrace{
        \| \bm{c}_{k^*} - \text{sg} (\bm{z}) \|_F^2 +
        \beta \cdot \| \bm{z} - \text{sg} (\bm{c}_{k^*})\|_F^2.
    }_{\mathcal{L}_{commit}}
    $$

Note:
1. STE çš„å¼•å…¥ä¼šå¯¼è‡´ä¼ å› Encoder çš„æ¢¯åº¦ä¸å¤ªå‡†ç¡®;
2. Codebook çš„å­¦ä¹ ä»…ä»…ä¾èµ–äº Commitment Loss.

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### VQ-GAN

- å›¾ç‰‡ Token åŒ– + Next-token prediction $p(s_i | s_{< i}, \textcolor{red}{condition})$

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250311144000.png" alt="Image" style="max-width: 100%; height: auto;margin: 0 auto;">
</div>

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Esser P., et al. Taming Transformers for High-Resolution Image Synthesis. CVPR, 2021.</p>
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Why Discrete Representation Learning?

âœ… **ç¦»æ•£ç¼–ç **æ›´é€‚åˆ**ç”Ÿæˆå¼**XXX

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $\textcircled{\small 1}$ æ›´å®¹æ˜“ä½œä¸º<u>è¯è¡¨</u>çš„æ‹“å±•

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $\textcircled{\small 2}$ (Rec) æœ‰å¸Œæœ›æ‰“ç ´<u>æœ€è¿‘é‚»åŒ¹é…</u>çš„é™åˆ¶

âœ… **å¯æ§æ€§:** ç±»ä¼¼è‡ªç„¶è¯­è¨€çš„å¯æ“æ§æ€§

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $\textcircled{\small 1}$ ç†è§£å„ç¼–ç çš„å«ä¹‰å¹¶åŠ ä»¥æ“æ§

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $\textcircled{\small 2}$ (Rec) ç”Ÿæˆçš„å¤šæ ·æ€§

âœ… **é²æ£’æ€§:** é«˜æ•ˆçš„ä¿¡æ¯å‹ç¼©å¸¦æ¥æƒŠè‰³çš„å»å™ªæ•ˆæœ

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Challenges

- **Undesirable Gradient Estimator:**

<div class="slide-img">
  <img 
  src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250707152059.png" 
  alt="Image" 
  style="max-width: 90%; height: auto;margin: 0 auto;">
</div>


- **Codebook Collapse:** Low codebook usage
    1. Codebook ä¸­éƒ¨åˆ†å‘é‡è¿‡äºæ¥è¿‘è€Œé€ æˆçš„å†—ä½™
    2. Codebook ä¸­éƒ¨åˆ†å‘é‡ç”±äºè®­ç»ƒå§‹ç»ˆåŒ¹é…ä¸åˆ° $\bm{z}$ å¯¼è‡´çš„å†—ä½™

Note:
VQ-VAE å¹¿ä¸ºäººçŸ¥çš„å‡ ä¸ªé—®é¢˜

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Solutions

- **Undesirable Gradient Estimator:**
    1. Gumbel-softmax estimator${}^{\text{[1]}}$;
    2. Rotation-trick estimator${}^{\text{[2]}}$

- **Codebook Collapse:**
    1. å¯¹äº codebook é‡‡ç”¨ K-means ++ åˆå§‹åŒ–${}^{\text{[3]}}$;
    2. Fixed Codebook${}^{\text{[4]}}$;
    3. Fixed Codebook + Trainable linear transformation${}^{\text{[5]}}$

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">[1] Takida Y., et al. SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization. ICML, 2022.</p>
    <p style="margin: 2px 0;">[2] Fifty C., et al. Restructuring Vector Quantization with the Rotation Trick. ICLR, 2025.</p>
    <p style="margin: 2px 0;">[3] Lancucki A., et al. Robust Training of Vector Quantized Bottleneck Models. 2020.</p>
    <p style="margin: 2px 0;">[4] Mentzer F., et al. Finite Scalar Quantization: VQ-VAE Made Simple. 2023.</p>
    <p style="margin: 2px 0;">[5] Zhu Y., et al. Addressing Representation Collapse in Vector Quantized Models with One Linear Layer. 2024.</p>
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Rotation Trick

- 'æ—‹è½¬' $\nabla_{q} \mathcal{L}$ å¾—åˆ° $\nabla_{z} \mathcal{L}$ æ»¡è¶³

    $$
    \angle (\bm{z}, \nabla_z \mathcal{L}) = \angle(\bm{q}, \nabla_q \mathcal{L}).
    $$

<div class="slide-img">
  <img 
  src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250612151216.png" 
  alt="Image" 
  style="max-width: 80%; height: auto;margin: 0 auto;">
</div>

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">[2] Fifty C., et al. Restructuring Vector Quantization with the Rotation Trick. ICLR, 2025.</p>
</div>

Note:
Rotation Trick å¸Œæœ›æ¢¯åº¦å’Œå‘é‡å¤¹è§’ä¸€è‡´.

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Rotation Trick


- ç­‰ä»·äºåˆ©ç”¨ 'æ—‹è½¬' çŸ©é˜µ $R$:

    $$
    \bm{q} = \text{sg}[\gamma R] \bm{z} + \text{sg}[\bm{c} - rR \bm{z}], \quad \textcolor{red}{R \bm{z} / \|\bm{z}\| = \bm{c} / \|\bm{c}\|}
    $$

- **Householder transformation:** ç»™å®šå‘é‡ $\bm{v}$ åŠè¿‡åŸç‚¹çš„æ­£äº¤å¹³é¢ $\bm{v}^{\perp} := \{\bm{u}: \bm{u}^T \bm{v} = 0\}$, å‘é‡ $\bm{x}$ å…³äº $\bm{v}^{\perp}$ çš„**åå°„**ä¸º

    $$
    \underbrace{\Big(I - 2 \frac{\bm{v} \bm{v}^T}{\|\bm{v}\|^2} \Big)}_{\text{Householder matrix } P} \bm{x}
    $$

- **æ€§è´¨:** $\bm{x} = \alpha \bm{v}^{\perp} + \beta \bm{v} \rightarrow P\bm{x} = \alpha \bm{v}^{\perp} \textcolor{red}{-} \beta \bm{v}$

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Reflection

$$
R = \left(I - 2 \frac{\bm{r}\bm{r}^T}{\|\bm{r}\|^2} \right), \quad \bm{r} := \frac{\bm{z}}{\|\bm{z}\|} - \frac{\bm{c}}{\|\bm{c}\|}
$$

<div class="slide-img">
  <img 
  src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250612173718.png" 
  alt="Image" 
  style="max-width: 90%; height: auto;margin: 0 auto;">
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Rotation

$$
R = \left(I - 2 \frac{\bm{c}\bm{c}^T}{\|\bm{c}\|^2} \right) \left(I - 2 \frac{\bm{r}\bm{r}^T}{\|\bm{r}\|^2} \right), \quad \bm{r} := \frac{\bm{z}}{\|\bm{z}\|} + \frac{\bm{c}}{\|\bm{c}\|}
$$

<div class="slide-img">
  <img 
  src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250612173750.png" 
  alt="Image" 
  style="max-width: 80%; height: auto;margin: 0 auto;">
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### STE vs Rotation vs Reflection


<div class="slide-cols">

- **STE:** $\nabla_{z} \mathcal{L} \equiv \nabla_{q} \mathcal{L}$

- **Rotation:** $\bm{z}$ åŸºæœ¬ä¸Šä¸ $\bm{q}$ çš„æ›´æ–°"è¡Œä¸º"ä¿æŒä¸€è‡´

- **Reflection:** $\bm{z}$ åŸºæœ¬ä¸Šä¸ $\bm{q}$ çš„æ›´æ–°"è¡Œä¸º"å¯èƒ½éå¸¸ä¸ä¸€è‡´

<div class="slide-cols-4">

</div>

<div class="slide-cols-6">

<div class="slide-img">
  <img 
  src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250612175428.png" 
  alt="Image" 
  style="max-width: 120%; height: auto;margin: 0 auto;">
</div>

</div>

</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Rotation Trick

ğŸŒŸ Rotation trick:

$$
\mathbf{q} = \text{sg}\Big[ \frac{\|\bm{c}\|}{\|\bm{z}\|} R \Big] \bm{z} \textcolor{red}{+ 0}
$$

ğŸŒŸ å†…ç§¯ä¸å˜æ€§ (â“$\textcolor{red}{+0}$):

$$
\langle \nabla_{z} \mathcal{L}, \bm{z} \rangle
=\langle \frac{\|\bm{c}\|}{\|\bm{z}\|} R^T \nabla_q \mathcal{L}, \bm{z} \rangle
=\langle \nabla_q \mathcal{L}, \frac{\|\bm{c}\|}{\|\bm{z}\|} R \bm{z} \rangle
=\langle \nabla_q \mathcal{L}, \bm{q} \rangle
$$


</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Residual Quantization (RQ-VAE)


ğŸ˜ $\text{Size}\textcolor{red}{\downarrow} \longrightarrow$ è¡¨è¾¾èƒ½åŠ›$\textcolor{red}{\downarrow}$ &nbsp; **vs** &nbsp; $\text{Size}\textcolor{green}{\uparrow} \longrightarrow$ Collapse$\textcolor{red}{\uparrow}$

- **RQ-VAE:**

    $$
    \bm{z} 
    \overset{\phi}{\rightarrow} \textcolor{red}{\bm{c}_{k_1}}
    \overset{\bm{z} - \bm{c}_{k_1}}{\longrightarrow} \bm{r}_1
    \overset{\phi}{\rightarrow} \textcolor{red}{\bm{c}_{k_2}}
    \overset{\bm{r}_1 - \bm{c}_{k_2}}{\longrightarrow} \bm{r}_2
    \rightarrow \cdots
    $$

- **è¿ç»­è¿‘ä¼¼:**

    $$
    \bm{q} = \bm{z} + \text{sg}\Big(\sum_{i=1}^{N} \bm{c}_{k_i} - \bm{z} \Big)
    $$


- **ç¦»æ•£ç¼–ç :** $(k_1, k_2, \ldots, k_N)$

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Lee D., et al. Autoregressive Image Generation using Residual Quantization. CVPR, 2022.</p>
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Fixed Codebook

- **å›ºå®š** Codebook ä¸º (size: $|\mathcal{C}| = (2 \lfloor L / 2 \rfloor + 1)^d$):

    $$
    \mathcal{C} = \{-\lfloor L / 2 \rfloor, -\lfloor L / 2 \rfloor + 1, \ldots, 0, \ldots \lfloor L / 2 \rfloor - 1, \lfloor L / 2 \rfloor\}^{d}.
    $$

- æ¯”å¦‚ $L = 3, d=3$:

    $$
    \mathcal{C} = \{
        (-1, -1, -1),
        (-1, -1, 0),
        \ldots,
        (1, 1, 1)
    \}.
    $$

- é‡åŒ–:

    $$
    \bm{q} =  
    \textcolor{red}{\text{round}} \big(
        \textcolor{blue}{\tanh} (\bm{z})
    \big).
    $$

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Mentzer F., et al. Finite Scalar Quantization: VQ-VAE Made Simple. 2023.</p>
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### SimVQ

<div class="slide-img">
  <img 
  src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250615103519.png" 
  alt="Image" 
  style="max-width: 100%; height: auto;margin: 0 auto;">
</div>

ğŸ˜ Codebook æ¯ä¸ªæ‰¹æ¬¡ä»…å°‘é‡å‘é‡å¾—åˆ°è®­ç»ƒ.

ğŸ˜„ SimVQ å›ºå®š Codebook ä»…è®­ç»ƒä¸€ä¸ª Linear Transformation $W$:

$$
\mathcal{C} \longrightarrow \{W \bm{c}_1, W \bm{c}_2, \ldots, W \bm{c}_K\}
$$

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">[5] Zhu Y., et al. Addressing Representation Collapse in Vector Quantized Models with One Linear Layer. 2024.</p>
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->


<section data-markdown>
<textarea data-template>

### TIGER


- **ä¼ ç»Ÿæ¨è (matching):**

    $$
    \bm{e}_u^T \bm{e}_v, \quad v \in \mathcal{V}.
    $$

- **ç”Ÿæˆå¼æ¨è:**

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250316175859.png" alt="Image" style="max-width: 80%; height: auto;margin: 0 auto;">
</div>


<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Rajput S., et al. Recommender Systems with Generative Retrieval. NeurIPS, 2023.</p>
</div>

</textarea>
</section>



<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### TIGER


- **ç”Ÿæˆå¼æ¨è (T5-based):**

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250316180725.png" alt="Image" style="max-width: 100%; height: auto;margin: 0 auto;">
</div>

- **Beam Search** $\overset{?}{\gg}$ **Approximate Nearest Neighbor**

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Beam Searchâ“

<div class="slide-cols">

<!-- left -->
<div class="slide-col-6">

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250707105044.png" 
  alt="Image" 
  style="max-width: 100%; height: auto;margin: 0 auto;">
</div>

</div>

<!-- right -->
<div class="slide-col-4">

- Amazon2014Beauty_1000_LOU

- #Users: 12,595 #Items: 75,253

- **Encoder:** All-MiniLM-L12-V2

- **Attributes:** (title, categories, brand)

- #Blocks$\textcolor{green}{\uparrow}$ $\longrightarrow$ #Invalids $\textcolor{green}{\downarrow}$

</div>

</div>

<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Zheng B., et al. Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation. ICDE, 2024.</p>
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Cold-Start Item Recommendationâ“


- Cold-start items å¯ç›´æ¥ç¼–ç , ä½†

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250327143851.png" 
  alt="Image" 
  style="max-width: 80%; height: auto;margin: 0 auto;">
</div>

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250327145319.png" 
  alt="Image" 
  style="max-width: 65%; height: auto;margin: 0 auto;">
</div>



<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Yang L., et al. Unifying Generative and Dense Retrieval for Sequential Recommendation. 2024.</p>
    <p style="margin: 2px 0;">Yang Y., et al. Sparse Meets Dense: Unified Generative Recommendations with Cascaded Sparse-Dense Representations. 2025.</p>
</div>

Note: 
è™½ç„¶åº”ç”¨ VQ å¯ä»¥å¾ˆå¥½åœ°æ”¯æŒå†·å¯åŠ¨dçš„å•†å“ (å¯ä»¥ç›¸å½“æ–¹ä¾¿åœ°è¿›è¡Œç¼–ç ), ä½†æ˜¯ LIGER å‘ç°, åˆ©ç”¨ VQ è®­ç»ƒçš„éå¸¸å®¹æ˜“è¿‡æ‹Ÿåˆåˆ°å‡ºç°è¿‡çš„ç»„åˆä¸­å», åè€Œå†·å¯åŠ¨çš„æ•ˆæœç‰¹åˆ«å·®.

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### RQ-VAE vs (Hierarchical/Residual) KMeansâ“


- RQ-VAE ç›¸è¾ƒäº (Hierarchical/Residual) KMeans çš„ä¼˜åŠ¿?

||HR@1|HR@5|HR@10|NDCG@5|NDCG@10|
|:-:|:-:|:-:|:-:|:-:|:-:|
|Random|0.0025|0.0080|0.0114|0.0052|0.0063|
|KMeans|0.0038|**0.0154**|**0.0246**|**0.0096**|**0.0126**|
|STE|0.0023|0.0111|0.0188|0.0067|0.0091|
|Rotation|**0.0041**|0.0122|0.0195|0.0083|0.0106|
|SimVQ|0.0029|0.0092|0.0164|0.0060|0.0083|


<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Wang Y., et al. EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration. 2024.</p>
    <p style="margin: 2px 0;">OneRec Team. OneRec Technical Report. 2025.</p>
</div>


Note: 
å‚æ•°è¿˜æ²¡æœ‰ç»†è°ƒ.

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Semantic Features + Collaborative Signalsâ“


- å¾®è°ƒ Encoder:

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250624153117.png" 
  alt="Image" 
  style="max-width: 100%; height: auto;margin: 0 auto;">
</div>


<div class="slide-ref">
    <div style="width: 100px; height: 1px; background: black; margin-bottom: 5px;"></div>
    <p style="margin: 2px 0;">Luo X., et al. OneRec Team. OneRec Technical Report. 2024.</p>
    <p style="margin: 2px 0;">OneRec Team. OneRec Technical Report. 2025.</p>
</div>


Note: 
1. é€šè¿‡ miniCPM-V-8B å°†å¤šæ¨¡æ€ä¿¡æ¯æ•´åˆä¸º $\mathbf{M} \in \mathbb{R}^{N_M \times d_t}$ å¤§å°çš„ token vectors (per item).
2. é€šè¿‡ QFormer è¿›ä¸€æ­¥èåˆå¾—åˆ° $\mathbf{\tilde{M}} \in \mathbb{R}^{N_{\tilde{M}} \times d_t}$, é€šå¸¸ $N_{\tilde{M}} = 4$ (è€Œ $N_M = 1280$).
3. é€šè¿‡ item-item é—´çš„**ç›¸ä¼¼åº¦**æ„å»ºé«˜è´¨é‡çš„ item-pair dataset $\mathcal{D}_{pair}$, ç„¶åé€šè¿‡ item-item é—´çš„å¯¹æ¯”å­¦ä¹ æ¥ä¿ƒä½¿ item features èåˆè¿›è¿™éƒ¨åˆ†ä¿¡æ¯.
4. æ­¤å¤–, é¢å¤–å¼•å…¥ Caption loss, å³é€šè¿‡ LLaMA3 æ¥é¢„æµ‹ Caption, ä¿è¯ features ä¸ä¼šä¸¢å¤±å†…å®¹ä¿¡æ¯.

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### æ€»ç»“

- Vector Quantization: ä¸€ç§ä¼˜é›…çš„ Tokenizer

- **ä¼˜åŠ¿:**
    - (Encoder-Decoder) ç»Ÿä¸€çš„ç¦»æ•£è¡¨ç¤º
    - (Rec) å…·æœ‰ä¸€å®šçš„å¯è§£é‡Šæ€§
    - (Rec) ä¼¼ä¹èƒ½æ¿€å‘æ¨èåœºæ™¯çš„ Scaling èƒ½åŠ›

- **ä¸è¶³:**
    - (Encoder-Decoder) Undesirable gradient estimator
    - (Encoder-Decoder) Codebook collapse
    - (Rec) ä¼¼ä¹ä¸å¤ªæ“…é•¿å†·å¯åœºæ™¯ (å¦‚ä½•ä¿®æ­£ Beam search)
    - (Rec) RQ-VAE ä¼¼ä¹æ²¡æœ‰å¿…è¦

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Decoder-Encoder-XXX Vector Quantization

<div class="slide-img">
  <img src="https://raw.githubusercontent.com/MTandHJ/blog_source/master/images/20250709165402.png" 
  alt="Image" 
  style="max-width: 100%; height: auto;margin: 0 auto;">
</div>

</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

### Decoder-Encoder-XXX Vector Quantization

- å®éªŒç»“æœ:

||HR@1|HR@5|HR@10|NDCG@5|NDCG@10|
|:-:|:-:|:-:|:-:|:-:|:-:|
|Random|0.0025|0.0080|0.0114|0.0052|0.0063|
|KMeans|0.0038|**0.0154**|**0.0246**|**0.0096**|**0.0126**|
|Rotation|**0.0041**|0.0122|0.0195|0.0083|0.0106|
|DEX-VQ|0.0033|0.0126|0.0216|0.0079|0.0107|


</textarea>
</section>

<!-- --------------------------------------------------------- -->

<section data-markdown>
<textarea data-template>

<div style="
  display: flex;
  justify-content: center;
  align-items: center;
  height: 40%;
  font-size: 10rem;
">
  Thanks!
</div>

</textarea>
</section>

